/**
 * 
 */
package com.animal;

import java.io.File;
import java.util.Random;

import org.datavec.api.io.labels.ParentPathLabelGenerator;
import org.datavec.api.split.FileSplit;
import org.datavec.image.loader.NativeImageLoader;
import org.datavec.image.recordreader.ImageRecordReader;
import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.inputs.InputType;
import org.deeplearning4j.nn.conf.layers.ConvolutionLayer;
import org.deeplearning4j.nn.conf.layers.DenseLayer;
import org.deeplearning4j.nn.conf.layers.OutputLayer;
import org.deeplearning4j.nn.conf.layers.SubsamplingLayer;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.deeplearning4j.util.ModelSerializer;
import org.nd4j.linalg.activations.Activation;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import org.nd4j.linalg.dataset.api.preprocessor.ImagePreProcessingScaler;
import org.nd4j.linalg.learning.config.Adam;
import org.nd4j.linalg.lossfunctions.LossFunctions;

public class AnimalTrainer {
    private static final int IMAGE_HEIGHT = 64;
    private static final int IMAGE_WIDTH = 64;
    private static final int IMAGE_CHANNELS = 3;
    private static final int OUTPUT_CLASSES = 4;
    private static final int BATCH_SIZE = 32;
    private static final int EPOCHS = 10;
    
    
    public static void main(String[] args) throws Exception {
        // ë°ì´í„°ì…‹ ë¡œë“œ
        File dataDir = new File("training_data/dataset/train");
        
        
        FileSplit fileSplit = new FileSplit(dataDir, NativeImageLoader.ALLOWED_FORMATS, new Random(42));
        ParentPathLabelGenerator labelMaker = new ParentPathLabelGenerator();
        
        ImageRecordReader recordReader = new ImageRecordReader(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS, labelMaker);
        recordReader.initialize(fileSplit);
        System.out.println("ë°ì´í„° ê°œìˆ˜: " + recordReader.numLabels());
        
        DataSetIterator dataIter = new RecordReaderDataSetIterator(recordReader, BATCH_SIZE, 1, OUTPUT_CLASSES);
        dataIter.setPreProcessor(new ImagePreProcessingScaler(0, 1));

        // ëª¨ë¸ êµ¬ì„±
        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
            .seed(42)
            .updater(new Adam(0.001))  // âœ… Adam ì‚¬ìš©
            .weightInit(WeightInit.XAVIER)
            .list()
            .layer(0, new ConvolutionLayer.Builder(3, 3)
                .nIn(IMAGE_CHANNELS)
                .nOut(32)
                .stride(1, 1)
                .activation(Activation.RELU)
                .build())
            .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)
                .kernelSize(2, 2)
                .stride(2, 2)
                .build())
            .layer(2, new ConvolutionLayer.Builder(3, 3)
                .nOut(64)
                .stride(1, 1)
                .activation(Activation.RELU)
                .build())
            .layer(3, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)
                .kernelSize(2, 2)
                .stride(2, 2)
                .build())
            .layer(4, new DenseLayer.Builder()
                .nOut(128)
                .activation(Activation.RELU)
                .build())
            .layer(5, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
                .nOut(OUTPUT_CLASSES)
                .activation(Activation.SOFTMAX)
                .build())
            .setInputType(InputType.convolutional(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))
            .build();
        
        File modelFile = new File("animal_model.zip");
        MultiLayerNetwork model = null;
        if(modelFile.exists() == true) {
        	model = ModelSerializer.restoreMultiLayerNetwork(modelFile);
            System.out.println("âœ… ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.");
        }
        else {
        	model = new MultiLayerNetwork(conf);
        	 System.out.println("ğŸš€ ìƒˆ ëª¨ë¸ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.");
        }
        
        //MultiLayerNetwork model = new MultiLayerNetwork(conf);
        model.init();
        model.setListeners(new ScoreIterationListener(10));

        // ëª¨ë¸ í•™ìŠµ
        System.out.println("ğŸš€ í•™ìŠµ ì‹œì‘!");
        for (int i = 0; i < EPOCHS; i++) {
            model.fit(dataIter);
            System.out.println("âœ… Epoch " + (i + 1) + " ì™„ë£Œ!");
        }
        
        if(modelFile.exists() == true) {
        	ModelSerializer.writeModel(model, modelFile, true);
        	System.out.println("âœ… ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.");
        }
        else {
            // ëª¨ë¸ ì €ì¥
            model.save(new File("animal_model.zip"));
            System.out.println("ğŸ‰ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!");
        }

    }
}

